{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "import itertools\n",
    "from datetime import timedelta\n",
    "from pmdarima.arima.utils import nsdiffs\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "from statsmodels.tools.sm_exceptions import InterpolationWarning\n",
    "\n",
    "warnings.filterwarnings('ignore', category=InterpolationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a date range for one year (e.g., 2020)\n",
    "dates = pd.date_range(start='2020-01-01', end='2020-12-31', freq='D')\n",
    "\n",
    "# Define units and shifts (each combination will represent a separate series)\n",
    "units = ['Unit1', 'Unit2']\n",
    "shifts = ['Morning', 'Evening']\n",
    "\n",
    "data_list = []\n",
    "\n",
    "# Loop through each combination and each date\n",
    "for unit in units:\n",
    "    for shift in shifts:\n",
    "        # Define a different trend or base sales for each unit/shift if desired\n",
    "        # Here, we use a simple example where trend intensity varies by combination.\n",
    "        if unit == 'Unit1' and shift == 'Morning':\n",
    "            base, trend_factor = 100, 0.1\n",
    "        elif unit == 'Unit1' and shift == 'Evening':\n",
    "            base, trend_factor = 120, 0\n",
    "        elif unit == 'Unit2' and shift == 'Morning':\n",
    "            base, trend_factor = 90, 0.15\n",
    "        else:  # Unit2, Evening\n",
    "            base, trend_factor = 110, 0.25\n",
    "        \n",
    "        for date in dates:\n",
    "            weekday = date.day_name()\n",
    "            # Randomly designate a holiday (e.g., 10% chance)\n",
    "            holiday = np.random.choice([0, 1], p=[0.9, 0.1])\n",
    "            # Generate a synthetic sales value: base + trend (based on day of year) + random noise\n",
    "            day_of_year = date.timetuple().tm_yday\n",
    "            noise = np.random.normal(loc=0, scale=10)\n",
    "            sales = base + trend_factor * day_of_year + noise\n",
    "            \n",
    "            data_list.append({\n",
    "                'Date': date,\n",
    "                'Unit': unit,\n",
    "                'Shift': shift,\n",
    "                'WeekdayName': weekday,\n",
    "                'HolidayYN': holiday,\n",
    "                'Sales': sales\n",
    "            })\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Optional: Display the first few rows to verify the data\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the series\n",
    "\n",
    "# Group by Unit and Shift\n",
    "groups = df.groupby(['Unit', 'Shift'])\n",
    "\n",
    "# Loop through each group and plot the series\n",
    "for (unit, shift), group in groups:\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    plt.plot(group['Date'], group['Sales'], linestyle='-', label=f'{unit} {shift}')\n",
    "    plt.title(f'Sales Series for {unit} - {shift}')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Sales')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummies\n",
    "df = pd.get_dummies(df, columns = ['WeekdayName', 'HolidayYN'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to test stationarity and seasonal differencing needs\n",
    "def check_stationarity(series, kpss_alpha=0.05, m=7):\n",
    "    # KPSS test for stationarity (null hypothesis: series is stationary)\n",
    "    try:\n",
    "        stat, p_value, lags, crit = kpss(series, regression='c', nlags='auto')\n",
    "    except Exception:\n",
    "        # In case of error (e.g., very short series), assume stationarity\n",
    "        p_value = 1.0\n",
    "    difference = 1 if p_value < kpss_alpha else 0\n",
    "\n",
    "    # Seasonal differencing test using nsdiffs (based on Canova-Hansen)\n",
    "    seasonal_order = nsdiffs(series, m=m, test='ch')\n",
    "    seasonal_difference = 1 if seasonal_order > 0 else 0\n",
    "\n",
    "    return difference, seasonal_difference\n",
    "\n",
    "# Assuming df is your DataFrame with columns:\n",
    "# 'Date', 'Unit', 'Shift', 'WeekdayName', 'HolidayYN', 'Sales'\n",
    "results = []\n",
    "\n",
    "# Group the data by Unit and Shift\n",
    "for (unit, shift), group in df.groupby(['Unit', 'Shift']):\n",
    "    # Ensure the series is sorted by Date\n",
    "    group_sorted = group.sort_values('Date')\n",
    "    sales_series = group_sorted['Sales']\n",
    "    \n",
    "    # Check for unit root and seasonal unit root\n",
    "    diff, seas_diff = check_stationarity(sales_series)\n",
    "    \n",
    "    results.append({\n",
    "        'Unit': unit,\n",
    "        'Shift': shift,\n",
    "        'difference': diff,\n",
    "        'seasonal_difference': seas_diff\n",
    "    })\n",
    "\n",
    "# Create the resulting DataFrame\n",
    "stationary_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# Function to determine the non-seasonal differencing order (d)\n",
    "# using the KPSS test. We increase d until the series becomes stationary.\n",
    "# -------------------------------------------------------------\n",
    "def determine_differencing_order(series, alpha=0.05, max_d=2):\n",
    "    d = 0\n",
    "    series_to_test = series.copy()\n",
    "    while d <= max_d:\n",
    "        try:\n",
    "            statistic, p_value, n_lags, crit = kpss(series_to_test, regression='c', nlags=\"auto\")\n",
    "        except Exception as e:\n",
    "            print(f\"KPSS test error: {e}\")\n",
    "            break\n",
    "        # If p_value > alpha, the series is stationary\n",
    "        if p_value > alpha:\n",
    "            break\n",
    "        else:\n",
    "            d += 1\n",
    "            series_to_test = series_to_test.diff().dropna()\n",
    "    return d\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Function to determine the seasonal differencing order (D)\n",
    "# using the nsdiffs function from pmdarima.\n",
    "# -------------------------------------------------------------\n",
    "def determine_seasonal_differencing_order(series, seasonal_period=7, max_D=1):\n",
    "    D = nsdiffs(series, m=seasonal_period, max_D=max_D)\n",
    "    return D\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Function to create the difference dataframe.\n",
    "# For each Unit/Shift series, calculate d and D.\n",
    "# -------------------------------------------------------------\n",
    "def create_difference_dataframe(df, seasonal_period=7):\n",
    "    rows = []\n",
    "    for (unit, shift), group in df.groupby(['Unit', 'Shift']):\n",
    "        group = group.sort_values('Date')\n",
    "        series = group['Sales'].astype(float)\n",
    "        d = determine_differencing_order(series)\n",
    "        D = determine_seasonal_differencing_order(series, seasonal_period)\n",
    "        rows.append({\n",
    "            'Unit': unit,\n",
    "            'Shift': shift,\n",
    "            'Difference': d,\n",
    "            'SeasonalDifference': D\n",
    "        })\n",
    "    difference_df = pd.DataFrame(rows)\n",
    "    return difference_df\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Function to create the model parameters dataframe.\n",
    "# It uses candidate lists for p, q, P, Q and the computed d and D values.\n",
    "# -------------------------------------------------------------\n",
    "def create_model_parameters_dataframe(difference_df, \n",
    "                                        p_values=[0,1,2], \n",
    "                                        q_values=[0,1,2], \n",
    "                                        P_values=[0,1], \n",
    "                                        Q_values=[0,1], \n",
    "                                        seasonal_period=7):\n",
    "    rows = []\n",
    "    for _, row in difference_df.iterrows():\n",
    "        unit = row['Unit']\n",
    "        shift = row['Shift']\n",
    "        d = row['Difference']\n",
    "        D = row['SeasonalDifference']\n",
    "        model_number = 0\n",
    "        # Generate all combinations of (p, q, P, Q)\n",
    "        for p, q, P, Q in itertools.product(p_values, q_values, P_values, Q_values):\n",
    "            model_number += 1\n",
    "            # Build the SARIMAX parameter tuple:\n",
    "            # non-seasonal order: (p, d, q)\n",
    "            # seasonal order: (P, D, Q, seasonal_period)\n",
    "            model_params = {\n",
    "                'order': (p, d, q),\n",
    "                'seasonal_order': (P, D, Q, seasonal_period)\n",
    "            }\n",
    "            rows.append({\n",
    "                'Unit': unit,\n",
    "                'Shift': shift,\n",
    "                'ModelNumber': model_number,\n",
    "                'ModelParameters': model_params\n",
    "            })\n",
    "    model_parameters_df = pd.DataFrame(rows)\n",
    "    return model_parameters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "    \n",
    "# 1. Create the difference dataframe\n",
    "difference_df = create_difference_dataframe(df, seasonal_period=7)\n",
    "    \n",
    "# 2. Create the model parameters dataframe\n",
    "model_parameters_df = create_model_parameters_dataframe(difference_df, p_values=[0,1], q_values=[0,1], \n",
    "                                                        P_values=[0], Q_values=[0], seasonal_period=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_testing_date_ranges_dataframe(df, forecast_lengths=[7, 90], periods=3, shift_days=11):\n",
    "    \"\"\"\n",
    "    Create a DataFrame with testing date ranges for each unit/shift series.\n",
    "    \n",
    "    For each (Unit, Shift) group in the DataFrame:\n",
    "      - For each forecast_length (e.g., 7 or 90 days), generate a fixed number of periods (default 3).\n",
    "      - The first testing period ends on the maximum date in the series.\n",
    "      - Subsequent periods are obtained by shifting the end date to the left by shift_days (11 days).\n",
    "      - The start date is computed as end date - forecast_length + 1.\n",
    "      \n",
    "    Parameters:\n",
    "      df: pandas DataFrame containing at least the 'Date', 'Unit', and 'Shift' columns.\n",
    "      forecast_lengths: list of forecast lengths (in days) to create testing periods for.\n",
    "      periods: number of testing periods to generate for each forecast length.\n",
    "      shift_days: number of days to shift the testing period end date for each subsequent period.\n",
    "    \n",
    "    Returns:\n",
    "      A pandas DataFrame with columns: Unit, Shift, TestingPeriodNumber, ForecastLength, StartDate, EndDate.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for (unit, shift), group in df.groupby(['Unit', 'Shift']):\n",
    "        group = group.sort_values('Date')\n",
    "        max_date = group['Date'].max()\n",
    "        for forecast_length in forecast_lengths:\n",
    "            for period in range(1, periods + 1):\n",
    "                # Compute shift offset: period 1 uses 0-day offset, period 2 uses shift_days, etc.\n",
    "                shift_offset = (period - 1) * shift_days\n",
    "                period_end = max_date - pd.Timedelta(days=shift_offset)\n",
    "                period_start = period_end - pd.Timedelta(days=forecast_length - 1)\n",
    "                rows.append({\n",
    "                    'Unit': unit,\n",
    "                    'Shift': shift,\n",
    "                    'TestingPeriodNumber': f\"{forecast_length}_period_{period}\",\n",
    "                    'ForecastLength': forecast_length,\n",
    "                    'StartDate': period_start,\n",
    "                    'EndDate': period_end\n",
    "                })\n",
    "    testing_ranges_df = pd.DataFrame(rows)\n",
    "    return testing_ranges_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_ranges_df = create_testing_date_ranges_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# Utility function to compute error metrics.\n",
    "# -------------------------------------------------------------\n",
    "def compute_error_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    # Avoid division by zero in MAPE calculation:\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        mape = np.mean(np.abs((y_true - y_pred) / np.where(y_true == 0, 1, y_true))) * 100\n",
    "    return mae, mape, rmse\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Function to run model testing and collect the results.\n",
    "#\n",
    "# For each (Unit, Shift) group:\n",
    "#  1. For each testing period (defined by forecast_start and forecast_end)\n",
    "#     - Use all data before forecast_start as the training set.\n",
    "#     - Extract actual sales for the testing period.\n",
    "#  2. For each candidate model (from the model_parameters_df):\n",
    "#     - Fit a SARIMAX model on the training set.\n",
    "#     - Forecast for forecast_length days.\n",
    "#     - Compute MAE, MAPE, and RMSE comparing the forecast to the actual test data.\n",
    "#  3. Append the results to a list.\n",
    "#\n",
    "# Returns a DataFrame with columns:\n",
    "#   Unit, Shift, ForecastLength, ForecastStart, ForecastEnd,\n",
    "#   ModelParameters (string), MAE, MAPE, RMSE\n",
    "# -------------------------------------------------------------\n",
    "def run_model_testing(df, testing_date_ranges_df, model_parameters_df):\n",
    "    results = []\n",
    "    \n",
    "    # Loop over each testing period from our testing ranges dataframe.\n",
    "    for _, test_row in testing_date_ranges_df.iterrows():\n",
    "        unit = test_row['Unit']\n",
    "        shift = test_row['Shift']\n",
    "        forecast_start = test_row['StartDate']\n",
    "        forecast_end = test_row['EndDate']\n",
    "        forecast_length = test_row['ForecastLength']\n",
    "        \n",
    "        # Extract and sort data for the current unit and shift.\n",
    "        group_data = df[(df['Unit'] == unit) & (df['Shift'] == shift)].sort_values('Date')\n",
    "        # Set Date as the index and enforce a daily frequency\n",
    "        group_data = group_data.set_index('Date').asfreq('D')\n",
    "        \n",
    "        # Use all available data before the forecast start date as training.\n",
    "        train_data = group_data[group_data.index < forecast_start]\n",
    "        # Extract test data for the forecast period.\n",
    "        test_data = group_data[(group_data.index >= forecast_start) & (group_data.index <= forecast_end)]\n",
    "        \n",
    "        # Ensure we have a complete test period.\n",
    "        if len(test_data) < forecast_length or train_data.empty:\n",
    "            print(f\"Skipping Unit {unit} Shift {shift} period starting {forecast_start} due to insufficient data.\")\n",
    "            continue\n",
    "\n",
    "        # Get candidate models for the current unit/shift.\n",
    "        models_df = model_parameters_df[(model_parameters_df['Unit'] == unit) & (model_parameters_df['Shift'] == shift)]\n",
    "        \n",
    "        for _, model_row in models_df.iterrows():\n",
    "            model_params = model_row['ModelParameters']\n",
    "            order = model_params['order']\n",
    "            seasonal_order = model_params['seasonal_order']\n",
    "            \n",
    "            try:\n",
    "                # Fit SARIMAX on training data.\n",
    "                model = SARIMAX(train_data['Sales'], \n",
    "                                order=order, \n",
    "                                seasonal_order=seasonal_order,\n",
    "                                enforce_stationarity=False,\n",
    "                                enforce_invertibility=False)\n",
    "                model_fit = model.fit(disp=False, maxiter=200, method='lbfgs')\n",
    "                \n",
    "                # Forecast the specified number of steps.\n",
    "                forecast = model_fit.forecast(steps=forecast_length)\n",
    "                \n",
    "                # Ensure forecast and test data lengths match.\n",
    "                if len(forecast) != forecast_length:\n",
    "                    print(f\"Forecast length mismatch for Unit {unit} Shift {shift} with model {model_params}\")\n",
    "                    continue\n",
    "                \n",
    "                # Calculate error metrics.\n",
    "                mae, mape, rmse = compute_error_metrics(test_data['Sales'].values[:forecast_length], forecast.values)\n",
    "                \n",
    "                # Format the model parameters as a string (e.g., \"(1,0,0)x(1,0,0,7)\")\n",
    "                model_param_str = f\"({order[0]},{order[1]},{order[2]})x({seasonal_order[0]},{seasonal_order[1]},{seasonal_order[2]},{seasonal_order[3]})\"\n",
    "                \n",
    "                results.append({\n",
    "                    'Unit': unit,\n",
    "                    'Shift': shift,\n",
    "                    'ForecastLength': forecast_length,\n",
    "                    'ForecastStart': forecast_start,\n",
    "                    'ForecastEnd': forecast_end,\n",
    "                    'ModelParameters': model_param_str,\n",
    "                    'MAE': mae,\n",
    "                    'MAPE': mape,\n",
    "                    'RMSE': rmse\n",
    "                })\n",
    "            except Exception as e:\n",
    "                # In case the model fails to fit, log and continue.\n",
    "                print(f\"Error for Unit {unit} Shift {shift} with model {model_params}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # Convert results list into a DataFrame.\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_testing_results = run_model_testing(df, testing_ranges_df, model_parameters_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_testing_results.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
